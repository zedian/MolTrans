{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch import nn \n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, roc_curve, confusion_matrix, precision_score, recall_score, auc\n",
    "from sklearn.model_selection import KFold\n",
    "torch.manual_seed(1)    # reproducible torch:2 np:3\n",
    "np.random.seed(1)\n",
    "\n",
    "from config import BIN_config_DBPE\n",
    "from models import BIN_Interaction_Flat\n",
    "from stream import BIN_Data_Encoder\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_generator, model):\n",
    "    y_pred = []\n",
    "    y_label = []\n",
    "    model.eval()\n",
    "    loss_accumulate = 0.0\n",
    "    count = 0.0\n",
    "    for i, (d, p, d_mask, p_mask, label) in enumerate(data_generator):\n",
    "        score = model(d.long().cuda(), p.long().cuda(), d_mask.long().cuda(), p_mask.long().cuda())\n",
    "        \n",
    "        m = torch.nn.Sigmoid()\n",
    "        logits = torch.squeeze(m(score))\n",
    "        \n",
    "        loss_fct = torch.nn.BCELoss()            \n",
    "        \n",
    "        label = Variable(torch.from_numpy(np.array(label)).float()).cuda()\n",
    "\n",
    "        loss = loss_fct(logits, label)\n",
    "        \n",
    "        loss_accumulate += loss\n",
    "        count += 1\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        \n",
    "        label_ids = label.to('cpu').numpy()\n",
    "        y_label = y_label + label_ids.flatten().tolist()\n",
    "        y_pred = y_pred + logits.flatten().tolist()\n",
    "        \n",
    "    loss = loss_accumulate/count\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_label, y_pred)\n",
    "\n",
    "    precision = tpr / (tpr + fpr)\n",
    "\n",
    "    f1 = 2 * precision * tpr / (tpr + precision + 0.00001)\n",
    "\n",
    "    thred_optim = thresholds[5:][np.argmax(f1[5:])]\n",
    "\n",
    "    print(\"optimal threshold: \" + str(thred_optim))\n",
    "\n",
    "    y_pred_s = [1 if i else 0 for i in (y_pred >= thred_optim)]\n",
    "\n",
    "    auc_k = auc(fpr, tpr)\n",
    "    print(\"AUROC:\" + str(auc_k))\n",
    "    print(\"AUPRC: \"+ str(average_precision_score(y_label, y_pred)))\n",
    "\n",
    "    cm1 = confusion_matrix(y_label, y_pred_s)\n",
    "    print('Confusion Matrix : \\n', cm1)\n",
    "    print('Recall : ', recall_score(y_label, y_pred_s))\n",
    "    print('Precision : ', precision_score(y_label, y_pred_s))\n",
    "\n",
    "    total1=sum(sum(cm1))\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : ', accuracy1)\n",
    "\n",
    "    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    print('Specificity : ', specificity1)\n",
    "\n",
    "    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)])\n",
    "    return roc_auc_score(y_label, y_pred), average_precision_score(y_label, y_pred), f1_score(y_label, outputs), y_pred, loss.item()\n",
    "\n",
    "\n",
    "def main(fold_n, lr):\n",
    "    config = BIN_config_DBPE()\n",
    "    \n",
    "    lr = lr\n",
    "    BATCH_SIZE = config['batch_size']\n",
    "    train_epoch = 10\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    model = BIN_Interaction_Flat(**config)\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model, dim = 0)\n",
    "            \n",
    "    opt = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    #opt = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n",
    "    \n",
    "    print('--- Data Preparation ---')\n",
    "    \n",
    "    params = {'batch_size': BATCH_SIZE,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 6, \n",
    "              'drop_last': True}\n",
    "\n",
    "    dataFolder = './dataset/BindingDB'\n",
    "    df_train = pd.read_csv(dataFolder + '/train.csv')\n",
    "    df_val = pd.read_csv(dataFolder + '/val.csv')\n",
    "    df_test = pd.read_csv(dataFolder + '/test.csv')\n",
    "    \n",
    "    training_set = BIN_Data_Encoder(df_train.indjex.values, df_train.Label.values, df_train)\n",
    "    training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "    validation_set = BIN_Data_Encoder(df_val.index.values, df_val.Label.values, df_val)\n",
    "    validation_generator = data.DataLoader(validation_set, **params)\n",
    "    \n",
    "    testing_set = BIN_Data_Encoder(df_test.index.values, df_test.Label.values, df_test)\n",
    "    testing_generator = data.DataLoader(testing_set, **params)\n",
    "    \n",
    "    # early stopping\n",
    "    max_auc = 0\n",
    "    model_max = copy.deepcopy(model)\n",
    "    \n",
    "    print('--- Go for Training ---')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    for epo in range(train_epoch):\n",
    "        model.train()\n",
    "        for i, (d, p, d_mask, p_mask, label) in enumerate(training_generator):\n",
    "            score = model(d.long().cuda(), p.long().cuda(), d_mask.long().cuda(), p_mask.long().cuda())\n",
    "\n",
    "            label = Variable(torch.from_numpy(np.array(label)).float()).cuda()\n",
    "            \n",
    "            loss_fct = torch.nn.BCELoss()\n",
    "            m = torch.nn.Sigmoid()\n",
    "            n = torch.squeeze(m(score))\n",
    "            \n",
    "            loss = loss_fct(n, label)\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            if (i % 100 == 0):\n",
    "                print('Training at Epoch ' + str(epo + 1) + ' iteration ' + str(i) + ' with loss ' + str(loss.cpu().detach().numpy()))\n",
    "            \n",
    "        # every epoch test\n",
    "        with torch.set_grad_enabled(False):\n",
    "            auc, auprc, f1, logits, loss = test(validation_generator, model)\n",
    "            if auc > max_auc:\n",
    "                model_max = copy.deepcopy(model)\n",
    "                max_auc = auc\n",
    "            \n",
    "            print('Validation at Epoch '+ str(epo + 1) + ' , AUROC: '+ str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1))\n",
    "    \n",
    "    print('--- Go for Testing ---')\n",
    "    try:\n",
    "        with torch.set_grad_enabled(False):\n",
    "            auc, auprc, f1, logits, loss = test(testing_generator, model_max)\n",
    "            print('Testing AUROC: ' + str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1) + ' , Test loss: '+str(loss))\n",
    "    except:\n",
    "        print('testing failed')\n",
    "    return model_max, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 0.6871528\n",
      "Training at Epoch 1 iteration 100 with loss 0.81716734\n",
      "Training at Epoch 1 iteration 200 with loss 0.60536927\n",
      "Training at Epoch 1 iteration 300 with loss 0.81561315\n",
      "Training at Epoch 1 iteration 400 with loss 0.5608501\n",
      "Training at Epoch 1 iteration 500 with loss 0.6886791\n",
      "Training at Epoch 1 iteration 600 with loss 0.59586835\n",
      "Training at Epoch 1 iteration 700 with loss 0.67609274\n",
      "Training at Epoch 1 iteration 800 with loss 0.6344186\n",
      "Training at Epoch 1 iteration 900 with loss 0.6722579\n",
      "Training at Epoch 1 iteration 1000 with loss 0.638059\n",
      "Training at Epoch 1 iteration 1100 with loss 0.48087722\n",
      "Training at Epoch 1 iteration 1200 with loss 0.59553003\n",
      "Training at Epoch 1 iteration 1300 with loss 0.5529174\n",
      "Training at Epoch 1 iteration 1400 with loss 0.67067695\n",
      "Training at Epoch 1 iteration 1500 with loss 0.4577648\n",
      "Training at Epoch 1 iteration 1600 with loss 0.6020538\n",
      "Training at Epoch 1 iteration 1700 with loss 0.5698266\n",
      "Training at Epoch 1 iteration 1800 with loss 0.5191946\n",
      "Training at Epoch 1 iteration 1900 with loss 0.72022164\n",
      "Training at Epoch 1 iteration 2000 with loss 0.5015118\n",
      "Training at Epoch 1 iteration 2100 with loss 0.80214703\n",
      "Training at Epoch 1 iteration 2200 with loss 0.5093545\n",
      "Training at Epoch 1 iteration 2300 with loss 0.52788234\n",
      "Training at Epoch 1 iteration 2400 with loss 0.83994484\n",
      "Training at Epoch 1 iteration 2500 with loss 0.67733705\n",
      "Training at Epoch 1 iteration 2600 with loss 0.52568537\n",
      "Training at Epoch 1 iteration 2700 with loss 0.7268578\n",
      "Training at Epoch 1 iteration 2800 with loss 0.5178365\n",
      "Training at Epoch 1 iteration 2900 with loss 0.4371994\n",
      "Training at Epoch 1 iteration 3000 with loss 0.51650375\n",
      "Training at Epoch 1 iteration 3100 with loss 0.5068053\n",
      "optimal threshold: 0.4118581712245941\n",
      "AUROC:0.8138037749221223\n",
      "AUPRC: 0.4259104945662232\n",
      "Confusion Matrix : \n",
      " [[3611 2106]\n",
      " [ 135  792]]\n",
      "Recall :  0.8543689320388349\n",
      "Precision :  0.2732919254658385\n",
      "Accuracy :  0.6627031908488862\n",
      "Sensitivity :  0.6316249781353857\n",
      "Specificity :  0.8543689320388349\n",
      "Validation at Epoch 1 , AUROC: 0.8138037749221223 , AUPRC: 0.4259104945662232 , F1: 0.48690894880812824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 2 iteration 0 with loss 0.51962197\n",
      "Training at Epoch 2 iteration 100 with loss 0.52024114\n",
      "Training at Epoch 2 iteration 200 with loss 0.7717838\n",
      "Training at Epoch 2 iteration 300 with loss 0.750285\n",
      "Training at Epoch 2 iteration 400 with loss 0.5697961\n",
      "Training at Epoch 2 iteration 500 with loss 0.40790504\n",
      "Training at Epoch 2 iteration 600 with loss 0.5260252\n",
      "Training at Epoch 2 iteration 700 with loss 0.51975924\n",
      "Training at Epoch 2 iteration 800 with loss 0.45560312\n",
      "Training at Epoch 2 iteration 900 with loss 0.692677\n",
      "Training at Epoch 2 iteration 1000 with loss 0.8300811\n",
      "Training at Epoch 2 iteration 1100 with loss 0.47024906\n",
      "Training at Epoch 2 iteration 1200 with loss 0.52743983\n",
      "Training at Epoch 2 iteration 1300 with loss 0.82229483\n",
      "Training at Epoch 2 iteration 1400 with loss 0.38334316\n",
      "Training at Epoch 2 iteration 1500 with loss 0.43084177\n",
      "Training at Epoch 2 iteration 1600 with loss 0.45551434\n",
      "Training at Epoch 2 iteration 1700 with loss 0.7743418\n",
      "Training at Epoch 2 iteration 1800 with loss 0.33703822\n",
      "Training at Epoch 2 iteration 1900 with loss 0.4643397\n",
      "Training at Epoch 2 iteration 2000 with loss 0.7135576\n",
      "Training at Epoch 2 iteration 2100 with loss 0.37738612\n",
      "Training at Epoch 2 iteration 2200 with loss 0.34150863\n",
      "Training at Epoch 2 iteration 2300 with loss 0.53538585\n",
      "Training at Epoch 2 iteration 2400 with loss 0.44797635\n",
      "Training at Epoch 2 iteration 2500 with loss 0.58698916\n",
      "Training at Epoch 2 iteration 2600 with loss 0.831644\n",
      "Training at Epoch 2 iteration 2700 with loss 0.5936903\n",
      "Training at Epoch 2 iteration 2800 with loss 0.45241678\n",
      "Training at Epoch 2 iteration 2900 with loss 0.7229109\n",
      "Training at Epoch 2 iteration 3000 with loss 0.6996368\n",
      "Training at Epoch 2 iteration 3100 with loss 0.5294635\n",
      "optimal threshold: 0.4332415461540222\n",
      "AUROC:0.8358532124425364\n",
      "AUPRC: 0.47711389544959537\n",
      "Confusion Matrix : \n",
      " [[4049 1668]\n",
      " [ 163  764]]\n",
      "Recall :  0.8241639697950378\n",
      "Precision :  0.31414473684210525\n",
      "Accuracy :  0.7244130042143287\n",
      "Sensitivity :  0.7082385866713311\n",
      "Specificity :  0.8241639697950378\n",
      "Validation at Epoch 2 , AUROC: 0.8358532124425364 , AUPRC: 0.47711389544959537 , F1: 0.4916241806263657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 3 iteration 0 with loss 0.54710495\n",
      "Training at Epoch 3 iteration 100 with loss 0.52779245\n",
      "Training at Epoch 3 iteration 200 with loss 0.5745724\n",
      "Training at Epoch 3 iteration 300 with loss 0.53866446\n",
      "Training at Epoch 3 iteration 400 with loss 0.3905522\n",
      "Training at Epoch 3 iteration 500 with loss 0.81826794\n",
      "Training at Epoch 3 iteration 600 with loss 0.36612353\n",
      "Training at Epoch 3 iteration 700 with loss 0.34689963\n",
      "Training at Epoch 3 iteration 800 with loss 0.56949043\n",
      "Training at Epoch 3 iteration 900 with loss 0.37182528\n",
      "Training at Epoch 3 iteration 1000 with loss 0.3675472\n",
      "Training at Epoch 3 iteration 1100 with loss 0.5133009\n",
      "Training at Epoch 3 iteration 1200 with loss 0.5902873\n",
      "Training at Epoch 3 iteration 1300 with loss 0.67270446\n",
      "Training at Epoch 3 iteration 1400 with loss 0.5616305\n",
      "Training at Epoch 3 iteration 1500 with loss 0.38696176\n",
      "Training at Epoch 3 iteration 1600 with loss 0.46595845\n",
      "Training at Epoch 3 iteration 1700 with loss 0.5107467\n",
      "Training at Epoch 3 iteration 1800 with loss 0.5412048\n",
      "Training at Epoch 3 iteration 1900 with loss 0.34199846\n",
      "Training at Epoch 3 iteration 2000 with loss 0.4901663\n",
      "Training at Epoch 3 iteration 2100 with loss 0.67181\n",
      "Training at Epoch 3 iteration 2200 with loss 0.46642786\n",
      "Training at Epoch 3 iteration 2300 with loss 0.5687111\n",
      "Training at Epoch 3 iteration 2400 with loss 0.3312491\n",
      "Training at Epoch 3 iteration 2500 with loss 0.592795\n",
      "Training at Epoch 3 iteration 2600 with loss 0.46659514\n",
      "Training at Epoch 3 iteration 2700 with loss 0.33867896\n",
      "Training at Epoch 3 iteration 2800 with loss 0.6252878\n",
      "Training at Epoch 3 iteration 2900 with loss 0.60629904\n",
      "Training at Epoch 3 iteration 3000 with loss 0.6799314\n",
      "Training at Epoch 3 iteration 3100 with loss 0.44446677\n",
      "optimal threshold: 0.3482508957386017\n",
      "AUROC:0.8606020689255668\n",
      "AUPRC: 0.48538648195275375\n",
      "Confusion Matrix : \n",
      " [[3547 2170]\n",
      " [  70  857]]\n",
      "Recall :  0.924487594390507\n",
      "Precision :  0.2831185992732078\n",
      "Accuracy :  0.6628537025888019\n",
      "Sensitivity :  0.6204302956095854\n",
      "Specificity :  0.924487594390507\n",
      "Validation at Epoch 3 , AUROC: 0.8606020689255668 , AUPRC: 0.48538648195275375 , F1: 0.519895872071402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 4 iteration 0 with loss 0.8484693\n",
      "Training at Epoch 4 iteration 100 with loss 0.38970795\n",
      "Training at Epoch 4 iteration 200 with loss 0.433564\n",
      "Training at Epoch 4 iteration 300 with loss 0.75303715\n",
      "Training at Epoch 4 iteration 400 with loss 0.3741634\n",
      "Training at Epoch 4 iteration 500 with loss 0.562875\n",
      "Training at Epoch 4 iteration 600 with loss 0.37542123\n",
      "Training at Epoch 4 iteration 700 with loss 0.581832\n",
      "Training at Epoch 4 iteration 800 with loss 0.42504066\n",
      "Training at Epoch 4 iteration 900 with loss 0.6865419\n",
      "Training at Epoch 4 iteration 1000 with loss 0.7631142\n",
      "Training at Epoch 4 iteration 1100 with loss 0.90158474\n",
      "Training at Epoch 4 iteration 1200 with loss 0.30134374\n",
      "Training at Epoch 4 iteration 1300 with loss 0.56051755\n",
      "Training at Epoch 4 iteration 1400 with loss 0.64133286\n",
      "Training at Epoch 4 iteration 1500 with loss 0.66662556\n",
      "Training at Epoch 4 iteration 1600 with loss 0.43326062\n",
      "Training at Epoch 4 iteration 1700 with loss 0.5318059\n",
      "Training at Epoch 4 iteration 1800 with loss 0.42001754\n",
      "Training at Epoch 4 iteration 1900 with loss 0.42362526\n",
      "Training at Epoch 4 iteration 2000 with loss 0.5902391\n",
      "Training at Epoch 4 iteration 2100 with loss 0.5168259\n",
      "Training at Epoch 4 iteration 2200 with loss 0.7244879\n",
      "Training at Epoch 4 iteration 2300 with loss 0.43501624\n",
      "Training at Epoch 4 iteration 2400 with loss 0.64590764\n",
      "Training at Epoch 4 iteration 2500 with loss 0.3882687\n",
      "Training at Epoch 4 iteration 2600 with loss 0.34506714\n",
      "Training at Epoch 4 iteration 2700 with loss 0.39260438\n",
      "Training at Epoch 4 iteration 2800 with loss 0.72794056\n",
      "Training at Epoch 4 iteration 2900 with loss 0.2756149\n",
      "Training at Epoch 4 iteration 3000 with loss 0.34147227\n",
      "Training at Epoch 4 iteration 3100 with loss 0.28777263\n",
      "optimal threshold: 0.3468979597091675\n",
      "AUROC:0.8618488472560215\n",
      "AUPRC: 0.4708379929806916\n",
      "Confusion Matrix : \n",
      " [[3731 1986]\n",
      " [  92  835]]\n",
      "Recall :  0.9007551240560949\n",
      "Precision :  0.29599432825239275\n",
      "Accuracy :  0.6872366044551474\n",
      "Sensitivity :  0.6526150078712611\n",
      "Specificity :  0.9007551240560949\n",
      "Validation at Epoch 4 , AUROC: 0.8618488472560215 , AUPRC: 0.4708379929806916 , F1: 0.5186300338727888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 5 iteration 0 with loss 0.32406163\n",
      "Training at Epoch 5 iteration 100 with loss 0.34840214\n",
      "Training at Epoch 5 iteration 200 with loss 0.82498133\n",
      "Training at Epoch 5 iteration 300 with loss 0.4349893\n",
      "Training at Epoch 5 iteration 400 with loss 0.8417536\n",
      "Training at Epoch 5 iteration 500 with loss 0.9277842\n",
      "Training at Epoch 5 iteration 600 with loss 0.25983262\n",
      "Training at Epoch 5 iteration 700 with loss 0.45074826\n",
      "Training at Epoch 5 iteration 800 with loss 0.34419656\n",
      "Training at Epoch 5 iteration 900 with loss 0.8725661\n",
      "Training at Epoch 5 iteration 1000 with loss 0.77098227\n",
      "Training at Epoch 5 iteration 1100 with loss 0.48937577\n",
      "Training at Epoch 5 iteration 1200 with loss 0.45705077\n",
      "Training at Epoch 5 iteration 1300 with loss 0.63410544\n",
      "Training at Epoch 5 iteration 1400 with loss 0.41360217\n",
      "Training at Epoch 5 iteration 1500 with loss 0.64831096\n",
      "Training at Epoch 5 iteration 1600 with loss 0.43756318\n",
      "Training at Epoch 5 iteration 1700 with loss 1.3613306\n",
      "Training at Epoch 5 iteration 1800 with loss 0.78348976\n",
      "Training at Epoch 5 iteration 1900 with loss 0.3555851\n",
      "Training at Epoch 5 iteration 2000 with loss 0.49716967\n",
      "Training at Epoch 5 iteration 2100 with loss 0.86242294\n",
      "Training at Epoch 5 iteration 2200 with loss 0.20694411\n",
      "Training at Epoch 5 iteration 2300 with loss 0.97508395\n",
      "Training at Epoch 5 iteration 2400 with loss 0.5331466\n",
      "Training at Epoch 5 iteration 2500 with loss 0.5040405\n",
      "Training at Epoch 5 iteration 2600 with loss 0.33373815\n",
      "Training at Epoch 5 iteration 2700 with loss 0.4504883\n",
      "Training at Epoch 5 iteration 2800 with loss 0.7054639\n",
      "Training at Epoch 5 iteration 2900 with loss 0.3096124\n",
      "Training at Epoch 5 iteration 3000 with loss 0.4613886\n",
      "Training at Epoch 5 iteration 3100 with loss 0.41278315\n",
      "optimal threshold: 0.352386474609375\n",
      "AUROC:0.8694998112142687\n",
      "AUPRC: 0.5016396450539138\n",
      "Confusion Matrix : \n",
      " [[3847 1870]\n",
      " [  78  849]]\n",
      "Recall :  0.9158576051779935\n",
      "Precision :  0.3122471496873851\n",
      "Accuracy :  0.7068031306441902\n",
      "Sensitivity :  0.6729053699492741\n",
      "Specificity :  0.9158576051779935\n",
      "Validation at Epoch 5 , AUROC: 0.8694998112142687 , AUPRC: 0.5016396450539138 , F1: 0.528533129069322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 6 iteration 0 with loss 0.4470876\n",
      "Training at Epoch 6 iteration 100 with loss 0.35323423\n",
      "Training at Epoch 6 iteration 200 with loss 0.49431992\n",
      "Training at Epoch 6 iteration 300 with loss 0.35381103\n",
      "Training at Epoch 6 iteration 400 with loss 0.8781048\n",
      "Training at Epoch 6 iteration 500 with loss 0.2780304\n",
      "Training at Epoch 6 iteration 600 with loss 0.26082212\n",
      "Training at Epoch 6 iteration 700 with loss 0.42571923\n",
      "Training at Epoch 6 iteration 800 with loss 0.48676598\n",
      "Training at Epoch 6 iteration 900 with loss 0.36938953\n",
      "Training at Epoch 6 iteration 1000 with loss 0.365251\n",
      "Training at Epoch 6 iteration 1100 with loss 0.6070029\n",
      "Training at Epoch 6 iteration 1200 with loss 0.7963381\n",
      "Training at Epoch 6 iteration 1300 with loss 0.3607612\n",
      "Training at Epoch 6 iteration 1400 with loss 0.41258818\n",
      "Training at Epoch 6 iteration 1500 with loss 0.9541172\n",
      "Training at Epoch 6 iteration 1600 with loss 0.65979743\n",
      "Training at Epoch 6 iteration 1700 with loss 0.6285771\n",
      "Training at Epoch 6 iteration 1800 with loss 0.43087822\n",
      "Training at Epoch 6 iteration 1900 with loss 0.40111896\n",
      "Training at Epoch 6 iteration 2000 with loss 0.26777658\n",
      "Training at Epoch 6 iteration 2100 with loss 0.8776568\n",
      "Training at Epoch 6 iteration 2200 with loss 0.6696141\n",
      "Training at Epoch 6 iteration 2300 with loss 1.1038618\n",
      "Training at Epoch 6 iteration 2400 with loss 0.5314579\n",
      "Training at Epoch 6 iteration 2500 with loss 0.2981817\n",
      "Training at Epoch 6 iteration 2600 with loss 1.1301684\n",
      "Training at Epoch 6 iteration 2700 with loss 0.5101948\n",
      "Training at Epoch 6 iteration 2800 with loss 0.6080096\n",
      "Training at Epoch 6 iteration 2900 with loss 0.38846755\n",
      "Training at Epoch 6 iteration 3000 with loss 0.39060086\n",
      "Training at Epoch 6 iteration 3100 with loss 0.62944674\n",
      "optimal threshold: 0.35435643792152405\n",
      "AUROC:0.8779714883542508\n",
      "AUPRC: 0.5375282522815904\n",
      "Confusion Matrix : \n",
      " [[3679 2038]\n",
      " [  66  861]]\n",
      "Recall :  0.9288025889967637\n",
      "Precision :  0.29699896516040014\n",
      "Accuracy :  0.6833232992173389\n",
      "Sensitivity :  0.6435193283190485\n",
      "Specificity :  0.9288025889967637\n",
      "Validation at Epoch 6 , AUROC: 0.8779714883542508 , AUPRC: 0.5375282522815904 , F1: 0.5196795541623128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 7 iteration 0 with loss 0.27598897\n",
      "Training at Epoch 7 iteration 100 with loss 0.36331037\n",
      "Training at Epoch 7 iteration 200 with loss 0.39220363\n",
      "Training at Epoch 7 iteration 300 with loss 0.31749249\n",
      "Training at Epoch 7 iteration 400 with loss 0.500906\n",
      "Training at Epoch 7 iteration 500 with loss 0.58215576\n",
      "Training at Epoch 7 iteration 600 with loss 0.31948668\n",
      "Training at Epoch 7 iteration 700 with loss 0.24961579\n",
      "Training at Epoch 7 iteration 800 with loss 0.22053972\n",
      "Training at Epoch 7 iteration 900 with loss 0.91278183\n",
      "Training at Epoch 7 iteration 1000 with loss 0.3854853\n",
      "Training at Epoch 7 iteration 1100 with loss 0.60668933\n",
      "Training at Epoch 7 iteration 1200 with loss 0.4602598\n",
      "Training at Epoch 7 iteration 1300 with loss 0.68827295\n",
      "Training at Epoch 7 iteration 1400 with loss 0.22113997\n",
      "Training at Epoch 7 iteration 1500 with loss 0.27772754\n",
      "Training at Epoch 7 iteration 1600 with loss 0.3963105\n",
      "Training at Epoch 7 iteration 1700 with loss 0.50470126\n",
      "Training at Epoch 7 iteration 1800 with loss 0.38889554\n",
      "Training at Epoch 7 iteration 1900 with loss 0.63179475\n",
      "Training at Epoch 7 iteration 2000 with loss 0.6854456\n",
      "Training at Epoch 7 iteration 2100 with loss 0.9501249\n",
      "Training at Epoch 7 iteration 2200 with loss 0.6888231\n",
      "Training at Epoch 7 iteration 2300 with loss 0.4326747\n",
      "Training at Epoch 7 iteration 2400 with loss 0.5612003\n",
      "Training at Epoch 7 iteration 2500 with loss 0.48965022\n",
      "Training at Epoch 7 iteration 2600 with loss 0.66900074\n",
      "Training at Epoch 7 iteration 2700 with loss 0.2877159\n",
      "Training at Epoch 7 iteration 2800 with loss 0.90778315\n",
      "Training at Epoch 7 iteration 2900 with loss 0.8493892\n",
      "Training at Epoch 7 iteration 3000 with loss 0.5920996\n",
      "Training at Epoch 7 iteration 3100 with loss 0.5731509\n",
      "optimal threshold: 0.3656984567642212\n",
      "AUROC:0.8749848811027275\n",
      "AUPRC: 0.5154096089585686\n",
      "Confusion Matrix : \n",
      " [[3901 1816]\n",
      " [  94  833]]\n",
      "Recall :  0.8985976267529665\n",
      "Precision :  0.31445828614571536\n",
      "Accuracy :  0.7125225767609874\n",
      "Sensitivity :  0.682350883330418\n",
      "Specificity :  0.8985976267529665\n",
      "Validation at Epoch 7 , AUROC: 0.8749848811027275 , AUPRC: 0.5154096089585686 , F1: 0.524777183600713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 8 iteration 0 with loss 0.19746466\n",
      "Training at Epoch 8 iteration 100 with loss 0.55472654\n",
      "Training at Epoch 8 iteration 200 with loss 0.35665208\n",
      "Training at Epoch 8 iteration 300 with loss 0.36032104\n",
      "Training at Epoch 8 iteration 400 with loss 0.22986762\n",
      "Training at Epoch 8 iteration 500 with loss 0.4929989\n",
      "Training at Epoch 8 iteration 600 with loss 0.37819165\n",
      "Training at Epoch 8 iteration 700 with loss 0.33332014\n",
      "Training at Epoch 8 iteration 800 with loss 0.43352863\n",
      "Training at Epoch 8 iteration 900 with loss 0.6094138\n",
      "Training at Epoch 8 iteration 1000 with loss 0.4214249\n",
      "Training at Epoch 8 iteration 1100 with loss 0.52009976\n",
      "Training at Epoch 8 iteration 1200 with loss 0.53572273\n",
      "Training at Epoch 8 iteration 1300 with loss 0.21465409\n",
      "Training at Epoch 8 iteration 1400 with loss 0.6888572\n",
      "Training at Epoch 8 iteration 1500 with loss 0.36735356\n",
      "Training at Epoch 8 iteration 1600 with loss 0.62447417\n",
      "Training at Epoch 8 iteration 1700 with loss 0.32431507\n",
      "Training at Epoch 8 iteration 1800 with loss 0.47547838\n",
      "Training at Epoch 8 iteration 1900 with loss 0.23469499\n",
      "Training at Epoch 8 iteration 2000 with loss 0.41009766\n",
      "Training at Epoch 8 iteration 2100 with loss 0.43287703\n",
      "Training at Epoch 8 iteration 2200 with loss 0.6258244\n",
      "Training at Epoch 8 iteration 2300 with loss 0.2485509\n",
      "Training at Epoch 8 iteration 2400 with loss 0.26971808\n",
      "Training at Epoch 8 iteration 2500 with loss 0.46284947\n",
      "Training at Epoch 8 iteration 2600 with loss 0.33377296\n",
      "Training at Epoch 8 iteration 2700 with loss 0.6229151\n",
      "Training at Epoch 8 iteration 2800 with loss 0.6091596\n",
      "Training at Epoch 8 iteration 2900 with loss 0.6803644\n",
      "Training at Epoch 8 iteration 3000 with loss 0.49498492\n",
      "Training at Epoch 8 iteration 3100 with loss 0.29860413\n",
      "optimal threshold: 0.4212312400341034\n",
      "AUROC:0.8748446834032153\n",
      "AUPRC: 0.5093488099564255\n",
      "Confusion Matrix : \n",
      " [[4214 1503]\n",
      " [ 125  802]]\n",
      "Recall :  0.8651564185544768\n",
      "Precision :  0.34793926247288504\n",
      "Accuracy :  0.7549668874172185\n",
      "Sensitivity :  0.7370998775581599\n",
      "Specificity :  0.8651564185544768\n",
      "Validation at Epoch 8 , AUROC: 0.8748446834032153 , AUPRC: 0.5093488099564255 , F1: 0.5269203158650395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 9 iteration 0 with loss 0.57086855\n",
      "Training at Epoch 9 iteration 100 with loss 1.0267323\n",
      "Training at Epoch 9 iteration 200 with loss 0.3175819\n",
      "Training at Epoch 9 iteration 300 with loss 0.47214982\n",
      "Training at Epoch 9 iteration 400 with loss 0.6876374\n",
      "Training at Epoch 9 iteration 500 with loss 0.54324603\n",
      "Training at Epoch 9 iteration 600 with loss 0.2655022\n",
      "Training at Epoch 9 iteration 700 with loss 0.7457869\n",
      "Training at Epoch 9 iteration 800 with loss 0.41463327\n",
      "Training at Epoch 9 iteration 900 with loss 0.32027906\n",
      "Training at Epoch 9 iteration 1000 with loss 0.6011503\n",
      "Training at Epoch 9 iteration 1100 with loss 0.46313846\n",
      "Training at Epoch 9 iteration 1200 with loss 0.7054145\n",
      "Training at Epoch 9 iteration 1300 with loss 0.24095881\n",
      "Training at Epoch 9 iteration 1400 with loss 0.59641695\n",
      "Training at Epoch 9 iteration 1500 with loss 0.9727119\n",
      "Training at Epoch 9 iteration 1600 with loss 0.14912638\n",
      "Training at Epoch 9 iteration 1700 with loss 0.35522285\n",
      "Training at Epoch 9 iteration 1800 with loss 0.28390306\n",
      "Training at Epoch 9 iteration 1900 with loss 0.77447724\n",
      "Training at Epoch 9 iteration 2000 with loss 0.36966062\n",
      "Training at Epoch 9 iteration 2100 with loss 0.6434225\n",
      "Training at Epoch 9 iteration 2200 with loss 0.7714768\n",
      "Training at Epoch 9 iteration 2300 with loss 0.39358914\n",
      "Training at Epoch 9 iteration 2400 with loss 1.0845032\n",
      "Training at Epoch 9 iteration 2500 with loss 0.25339356\n",
      "Training at Epoch 9 iteration 2600 with loss 0.73073256\n",
      "Training at Epoch 9 iteration 2700 with loss 0.44184625\n",
      "Training at Epoch 9 iteration 2800 with loss 0.612914\n",
      "Training at Epoch 9 iteration 2900 with loss 0.27771142\n",
      "Training at Epoch 9 iteration 3000 with loss 0.24141286\n",
      "Training at Epoch 9 iteration 3100 with loss 0.37043506\n",
      "optimal threshold: 0.342526912689209\n",
      "AUROC:0.8779874327763353\n",
      "AUPRC: 0.5369212797474433\n",
      "Confusion Matrix : \n",
      " [[3842 1875]\n",
      " [  79  848]]\n",
      "Recall :  0.9147788565264293\n",
      "Precision :  0.3114212265883217\n",
      "Accuracy :  0.705900060204696\n",
      "Sensitivity :  0.6720307853769459\n",
      "Specificity :  0.9147788565264293\n",
      "Validation at Epoch 9 , AUROC: 0.8779874327763353 , AUPRC: 0.5369212797474433 , F1: 0.5234237407537865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 10 iteration 0 with loss 0.3108026\n",
      "Training at Epoch 10 iteration 100 with loss 0.20334767\n",
      "Training at Epoch 10 iteration 200 with loss 0.34976935\n",
      "Training at Epoch 10 iteration 300 with loss 0.1901992\n",
      "Training at Epoch 10 iteration 400 with loss 0.5104041\n",
      "Training at Epoch 10 iteration 500 with loss 1.2161007\n",
      "Training at Epoch 10 iteration 600 with loss 0.3761418\n",
      "Training at Epoch 10 iteration 700 with loss 0.37896463\n",
      "Training at Epoch 10 iteration 800 with loss 0.92417085\n",
      "Training at Epoch 10 iteration 900 with loss 0.52304196\n",
      "Training at Epoch 10 iteration 1000 with loss 0.17293215\n",
      "Training at Epoch 10 iteration 1100 with loss 0.893134\n",
      "Training at Epoch 10 iteration 1200 with loss 0.23694442\n",
      "Training at Epoch 10 iteration 1300 with loss 0.2986547\n",
      "Training at Epoch 10 iteration 1400 with loss 0.3254029\n",
      "Training at Epoch 10 iteration 1500 with loss 0.6660339\n",
      "Training at Epoch 10 iteration 1600 with loss 0.34580365\n",
      "Training at Epoch 10 iteration 1700 with loss 0.31795412\n",
      "Training at Epoch 10 iteration 1800 with loss 0.9689735\n",
      "Training at Epoch 10 iteration 1900 with loss 0.34955555\n",
      "Training at Epoch 10 iteration 2000 with loss 0.42912096\n",
      "Training at Epoch 10 iteration 2100 with loss 0.8034222\n",
      "Training at Epoch 10 iteration 2200 with loss 0.8318377\n",
      "Training at Epoch 10 iteration 2300 with loss 0.35391992\n",
      "Training at Epoch 10 iteration 2400 with loss 0.44636634\n",
      "Training at Epoch 10 iteration 2500 with loss 0.8769454\n",
      "Training at Epoch 10 iteration 2600 with loss 0.4853426\n",
      "Training at Epoch 10 iteration 2700 with loss 0.28533527\n",
      "Training at Epoch 10 iteration 2800 with loss 0.72143185\n",
      "Training at Epoch 10 iteration 2900 with loss 0.37697035\n",
      "Training at Epoch 10 iteration 3000 with loss 0.13551116\n",
      "Training at Epoch 10 iteration 3100 with loss 0.7055323\n",
      "optimal threshold: 0.3530391454696655\n",
      "AUROC:0.8710445332426104\n",
      "AUPRC: 0.493779238166257\n",
      "Confusion Matrix : \n",
      " [[4099 1618]\n",
      " [ 106  821]]\n",
      "Recall :  0.8856526429341963\n",
      "Precision :  0.33661336613366133\n",
      "Accuracy :  0.74051776038531\n",
      "Sensitivity :  0.7169844323946125\n",
      "Specificity :  0.8856526429341963\n",
      "Validation at Epoch 10 , AUROC: 0.8710445332426104 , AUPRC: 0.493779238166257 , F1: 0.5351577347016344\n",
      "--- Go for Testing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/zdx/.pyenv/versions/meta-rl/lib/python3.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal threshold: 0.38340646028518677\n",
      "AUROC:0.8684323424695342\n",
      "AUPRC: 0.5230513730279391\n",
      "Confusion Matrix : \n",
      " [[8030 3353]\n",
      " [ 205 1700]]\n",
      "Recall :  0.8923884514435696\n",
      "Precision :  0.33643380170195925\n",
      "Accuracy :  0.7322396146899458\n",
      "Sensitivity :  0.7054379337608715\n",
      "Specificity :  0.8923884514435696\n",
      "Testing AUROC: 0.8684323424695342 , AUPRC: 0.5230513730279391 , F1: 0.5259831460674157 , Test loss: 0.47883719205856323\n",
      "1572.3170115947723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f77142f27d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fold 1\n",
    "#biosnap interaction times 1e-6, flat, batch size 64, len 205, channel 3, epoch 50\n",
    "s = time()\n",
    "model_max, loss_history = main(1, 5e-6)\n",
    "e = time()\n",
    "print(e-s)\n",
    "lh = list(filter(lambda x: x < 1, loss_history))\n",
    "plt.plot(lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.0, 2.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0.dev20211106+cu113\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BIN_config_DBPE()\n",
    "\n",
    "BATCH_SIZE = config['batch_size']\n",
    "\n",
    "params = {'batch_size': BATCH_SIZE,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 6, \n",
    "              'drop_last': True}\n",
    "\n",
    "dataFolder = './dataset/BIOSNAP/full_data'\n",
    "df_train = pd.read_csv(dataFolder + '/train.csv')\n",
    "df_val = pd.read_csv(dataFolder + '/val.csv')\n",
    "df_test = pd.read_csv(dataFolder + '/test.csv')\n",
    "\n",
    "training_set = BIN_Data_Encoder(df_train.index.values, df_train.Label.values, df_train)\n",
    "training_generator = data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>DrugBank ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Target Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>DB08533</td>\n",
       "      <td>P49862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC1=CN=C2N1C=CN=C2NCC1=CC=NC=C1</td>\n",
       "      <td>MARSLLLPLQILLLSLALETAGEEAQGDKIIDGAPCARGSHPWQVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>DB00755</td>\n",
       "      <td>P48443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C\\C(\\C=C\\C1=C(C)CCCC1(C)C)=C/C=C/C(/C)=C/C(O)=O</td>\n",
       "      <td>MYGNYSHFMKFPAGYGGSPGHTGSTSMSPSAALSTGKPMDSHPSYT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DB00361</td>\n",
       "      <td>O60218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[H][C@@]12N(C)C3=CC(OC)=C(C=C3[C@@]11CCN3CC=C[...</td>\n",
       "      <td>MATFVELSTKAKMPIVGLGTWKSPLGKVKEAVKVAIDAGYRHIDCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>DB01136</td>\n",
       "      <td>P08588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COC1=CC=CC=C1OCCNCC(O)COC1=CC=CC2=C1C1=CC=CC=C1N2</td>\n",
       "      <td>MGAGVLVLGASEPGNLSSAAPLPDGAATAARLLVPASPPASLLPPA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>DB06963</td>\n",
       "      <td>Q9Y691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[H][C@@](C)(NC1=CC2=C(C=N1)C(C)=NN2C1=CC=CC(CC...</td>\n",
       "      <td>MFIWTSGRTSSSYRHDEKRNIYQKIRDHDLLDKRKTVTALKAGEDR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1 DrugBank ID    Gene  Label  \\\n",
       "0           0             3               4     DB08533  P49862    0.0   \n",
       "1           1             4               5     DB00755  P48443    1.0   \n",
       "2           2             5               6     DB00361  O60218    0.0   \n",
       "3           3             7               8     DB01136  P08588    1.0   \n",
       "4           4             8               9     DB06963  Q9Y691    0.0   \n",
       "\n",
       "                                              SMILES  \\\n",
       "0                    CC1=CN=C2N1C=CN=C2NCC1=CC=NC=C1   \n",
       "1    C\\C(\\C=C\\C1=C(C)CCCC1(C)C)=C/C=C/C(/C)=C/C(O)=O   \n",
       "2  [H][C@@]12N(C)C3=CC(OC)=C(C=C3[C@@]11CCN3CC=C[...   \n",
       "3  COC1=CC=CC=C1OCCNCC(O)COC1=CC=CC2=C1C1=CC=CC=C1N2   \n",
       "4  [H][C@@](C)(NC1=CC2=C(C=N1)C(C)=NN2C1=CC=CC(CC...   \n",
       "\n",
       "                                     Target Sequence  \n",
       "0  MARSLLLPLQILLLSLALETAGEEAQGDKIIDGAPCARGSHPWQVA...  \n",
       "1  MYGNYSHFMKFPAGYGGSPGHTGSTSMSPSAALSTGKPMDSHPSYT...  \n",
       "2  MATFVELSTKAKMPIVGLGTWKSPLGKVKEAVKVAIDAGYRHIDCA...  \n",
       "3  MGAGVLVLGASEPGNLSSAAPLPDGAATAARLLVPASPPASLLPPA...  \n",
       "4  MFIWTSGRTSSSYRHDEKRNIYQKIRDHDLLDKRKTVTALKAGEDR...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'drug_encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'drug_encoding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25371/819507625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"drug_encoding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3455\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'drug_encoding'"
     ]
    }
   ],
   "source": [
    "df_train[\"drug_encoding\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRUG:\n",
      "torch.Size([16, 50])\n",
      "tensor([[ 3291,   300,   471,   117,  7522,  1804,   147,  2268,    91,  1855,\n",
      "            82,   211,   623,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    7,    66,  5763,    63,  3821, 13901,     7,    66,    11,  3901,\n",
      "             7,    66,   189,  5374,   156,    10,     7,    66,    11,  1077,\n",
      "          1176,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [10440, 18363,  6525, 20141,   569,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 5370,  4775,   363,   126,  1423,  1421,  5418,   623,   312,   300,\n",
      "          1423,    25,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1836,   117,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 2054,  1423,   166,   568,  1423, 21162, 17275,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 3344,    93,   179,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    7,    66,   409,  7877,   105,    69,   623, 13474,  2223,   623,\n",
      "           312,   300,    93,  1423,    25,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    7,    66,  3756,   221,   151,  2350,   160,  1423,  4804,   229,\n",
      "           298,    90,  6439,   177,   409,    94,  3901,     7,    66,    83,\n",
      "           154,  6862,  2354,  1176,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  839,  3329,   378,  5778,   623,    86,   312,   300,  9580,   240,\n",
      "           421,    77,   383,  1648,   179,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    7,    66,  2324,   868,    82,   397, 14071,  1154,   409,  4649,\n",
      "         10032,   151,    10,     7,    66,  2512,   377,   310,   393,   366,\n",
      "           508,  3765,   587,  5970,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 8216,   317,   358, 10325,   828,  1229,    22,  8991,   300,  1423,\n",
      "            25,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 4712,   176,    25,   312,   300,   493,  8650,  1156,   115,  1282,\n",
      "            28,  1143,    13,  2510,    22,  1423,   239,    82,   211,  1220,\n",
      "           126,   296,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1696,   161, 10981, 23499,   409,  2134,   563,    82,  6448,  4007,\n",
      "         10566,    93,   179,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  218, 23114,  4527,    82,  1602,   700,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  833,  1613,  1423,    93,  2794,   312,    93,   538,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "PROTEIN:\n",
      "torch.Size([16, 545])\n",
      "tensor([[1554,   27, 1180,  ...,    0,    0,    0],\n",
      "        [ 132,  816,  576,  ...,  103, 4994,   15],\n",
      "        [ 137,   81,  273,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 832,  434,  303,  ...,    0,    0,    0],\n",
      "        [ 592,  275,   95,  ...,    0,    0,    0],\n",
      "        [ 670,  101,   36,  ...,    0,    0,    0]])\n",
      "DRUG MASK:\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      "PROTEIN MASK:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "LABEL\n",
      "torch.Size([16])\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, (d, p, d_mask, p_mask, label) in enumerate(training_generator):\n",
    "    print(\"DRUG:\")\n",
    "    print(d.shape)\n",
    "    print(d)\n",
    "    print(\"PROTEIN:\")\n",
    "    print(p.shape)\n",
    "    print(p)\n",
    "    print(\"DRUG MASK:\")\n",
    "    print(d_mask)\n",
    "    print(\"PROTEIN MASK:\")\n",
    "    print(p_mask)\n",
    "    print(\"LABEL\")\n",
    "    print(label.shape)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-rl",
   "language": "python",
   "name": "meta-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
